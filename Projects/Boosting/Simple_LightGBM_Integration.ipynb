{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LightGBM` is a gradient boosting framework which outperforms `XGBoost` in training speeds, memory usage and size of the datasets it can handle. `LightGBM` is able to do so by using histogram-based algorithms to bucket continuous features into `discrete` bins during training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Wandb\n",
    "import wandb\n",
    "from wandb.lightgbm import wandb_callback, log_summary\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-06-08 21:15:51--  https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.train\n",
      "Resolving raw.githubusercontent.com... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com|2606:50c0:8000::154|:443... connected.\n",
      "WARNING: cannot verify raw.githubusercontent.com's certificate, issued by '/C=US/O=DigiCert Inc/CN=DigiCert TLS RSA SHA256 2020 CA1':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1228616 (1.2M) [text/plain]\n",
      "Saving to: 'regression.train'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4% 2.58M 0s\n",
      "    50K .......... .......... .......... .......... ..........  8% 3.35M 0s\n",
      "   100K .......... .......... .......... .......... .......... 12% 5.16M 0s\n",
      "   150K .......... .......... .......... .......... .......... 16% 4.00M 0s\n",
      "   200K .......... .......... .......... .......... .......... 20% 3.91M 0s\n",
      "   250K .......... .......... .......... .......... .......... 25% 4.67M 0s\n",
      "   300K .......... .......... .......... .......... .......... 29% 5.54M 0s\n",
      "   350K .......... .......... .......... .......... .......... 33% 3.46M 0s\n",
      "   400K .......... .......... .......... .......... .......... 37% 5.02M 0s\n",
      "   450K .......... .......... .......... .......... .......... 41% 6.40M 0s\n",
      "   500K .......... .......... .......... .......... .......... 45% 4.15M 0s\n",
      "   550K .......... .......... .......... .......... .......... 50% 6.77M 0s\n",
      "   600K .......... .......... .......... .......... .......... 54% 5.15M 0s\n",
      "   650K .......... .......... .......... .......... .......... 58% 6.26M 0s\n",
      "   700K .......... .......... .......... .......... .......... 62% 4.92M 0s\n",
      "   750K .......... .......... .......... .......... .......... 66% 5.65M 0s\n",
      "   800K .......... .......... .......... .......... .......... 70% 5.61M 0s\n",
      "   850K .......... .......... .......... .......... .......... 75% 6.76M 0s\n",
      "   900K .......... .......... .......... .......... .......... 79% 5.83M 0s\n",
      "   950K .......... .......... .......... .......... .......... 83% 7.27M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 87% 5.63M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 91% 7.69M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 95% 6.41M 0s\n",
      "  1150K .......... .......... .......... .......... ......... 100% 8.29M=0.2s\n",
      "\n",
      "2022-06-08 21:15:52 (5.03 MB/s) - 'regression.train' saved [1228616/1228616]\n",
      "\n",
      "--2022-06-08 21:15:52--  https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.test\n",
      "Resolving raw.githubusercontent.com... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com|2606:50c0:8000::154|:443... connected.\n",
      "WARNING: cannot verify raw.githubusercontent.com's certificate, issued by '/C=US/O=DigiCert Inc/CN=DigiCert TLS RSA SHA256 2020 CA1':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87767 (86K) [text/plain]\n",
      "Saving to: 'regression.test'\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 58% 14.9M 0s\n",
      "    50K .......... .......... .......... .....                100% 92.2M=0.004s\n",
      "\n",
      "2022-06-08 21:15:52 (22.9 MB/s) - 'regression.test' saved [87767/87767]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.train --no-check-certificate\n",
    "!wget https://raw.githubusercontent.com/microsoft/LightGBM/master/examples/regression/regression.test --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Create Dataset \n",
    "df_train = pd.read_csv('regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv('regression.test', header=None, sep='\\t')\n",
    "\n",
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)\n",
    "\n",
    "# Create Dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\ML\\WandbAI\\Examples\\Projects\\Boosting\\wandb\\run-20220608_212054-wlzsf0hk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/raghvender/lightgbm-wandb_example/runs/wlzsf0hk\" target=\"_blank\">scarlet-serenity-1</a></strong> to <a href=\"https://wandb.ai/raghvender/lightgbm-wandb_example\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/raghvender/lightgbm-wandb_example/runs/wlzsf0hk?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x256eabad150>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurations\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': ['rmse', 'l2', 'l1', 'huber'],\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "wandb.init(project='lightgbm-wandb_example', config=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Development\\Python\\Python3.10\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    }
   ],
   "source": [
    "# Train using wand_callback\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=30,\n",
    "                valid_sets=lgb_test,\n",
    "                valid_names=('validation'),\n",
    "                callbacks=[wandb_callback()],\n",
    "                early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Feature Importance and upload Model with `log_summary`\n",
    "\n",
    "`log_summary` will upload calculate and upload the feature importance import and (optionally) upload your trained model to W&B Artifacts so you can use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_summary(gbm, save_model_checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.43421275319941804\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "# Eval\n",
    "print('RMSE: ', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "wandb.log({'rmse_prediction': mean_squared_error(y_test, y_pred) ** 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bdc19e631764349b7c245a29bd438e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.087 MB of 0.087 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>rmse_prediction</td><td>▁</td></tr><tr><td>validation_huber</td><td>██▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>validation_l1</td><td>██▇▇▇▆▆▆▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>validation_l2</td><td>██▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>validation_rmse</td><td>██▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_iteration</td><td>30</td></tr><tr><td>iteration</td><td>29</td></tr><tr><td>rmse_prediction</td><td>0.43421</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">scarlet-serenity-1</strong>: <a href=\"https://wandb.ai/raghvender/lightgbm-wandb_example/runs/wlzsf0hk\" target=\"_blank\">https://wandb.ai/raghvender/lightgbm-wandb_example/runs/wlzsf0hk</a><br/>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220608_212054-wlzsf0hk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "377e50a5246b311701775dacc641cf519e90716189c79b110a6f1ebdee9e2206"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
